import os
from datetime import datetime, timedelta
from typing import Dict, List, Set, Tuple, Union
import logging
import re

import pygsheets
from googleapiclient.discovery import build
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from collections import defaultdict

# Constants
SCOPES = ['https://www.googleapis.com/auth/calendar.readonly']
SPREADSHEET_NAME = 'Matt-data-2024-test'
CALENDAR_ID = 'f4lathletics@gmail.com'

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


class GoogleAuth:
    @staticmethod
    def get_credentials() -> Credentials:
        logging.info("Checking for existing credentials...")
        creds = None
        if os.path.exists('token.json'):
            logging.info("Found token.json, loading credentials...")
            creds = Credentials.from_authorized_user_file('token.json', SCOPES)
        
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                logging.info("Refreshing expired credentials...")
                creds.refresh(Request())
            else:
                logging.info("No valid credentials found. Starting new auth flow...")
                flow = InstalledAppFlow.from_client_secrets_file('client_secret.json', SCOPES)
                creds = flow.run_local_server(port=0)
            logging.info("Saving new credentials...")
            with open('token.json', 'w') as token:
                token.write(creds.to_json())

        return creds


class SheetManager:
    def __init__(self, gc: pygsheets.client.Client, spreadsheet_name: str):
        self.gc = gc
        self.spreadsheet = self.gc.open(spreadsheet_name)

    def clear_or_create_tab(self, tab_name: str) -> pygsheets.Worksheet:
        try:
            sheet = self.spreadsheet.worksheet_by_title(tab_name)
            logging.info(f"Clearing existing '{tab_name}' tab...")
            sheet.clear()
        except pygsheets.exceptions.WorksheetNotFound:
            logging.info(f"Creating '{tab_name}' tab...")
            sheet = self.spreadsheet.add_worksheet(tab_name)
        return sheet

    def get_sheet(self, tab_name: str) -> pygsheets.Worksheet:
        try:
            return self.spreadsheet.worksheet_by_title(tab_name)
        except pygsheets.exceptions.WorksheetNotFound:
            raise ValueError(f"Worksheet '{tab_name}' not found.")


class CalendarManager:
    def __init__(self, service):
        self.service = service

    @staticmethod
    def get_previous_week_range() -> Tuple[datetime, datetime]:
        today = datetime.now().date()
        start_of_week = today - timedelta(days=today.weekday() + 7)
        end_of_week = start_of_week + timedelta(days=6)
        return datetime.combine(start_of_week, datetime.min.time()), datetime.combine(end_of_week, datetime.max.time())

    def fetch_calendar_events(self, start_of_week: datetime, end_of_week: datetime) -> List[Dict]:
        logging.info(f"Fetching events from {start_of_week.date()} to {end_of_week.date()}...")
        events_result = self.service.events().list(
            calendarId=CALENDAR_ID,
            timeMin=start_of_week.isoformat() + 'Z',
            timeMax=end_of_week.isoformat() + 'Z',
            singleEvents=True,
            orderBy='startTime'
        ).execute()
        events = events_result.get('items', [])
        logging.info(f"Found {len(events)} events.")
        return events


class DataProcessor:
    @staticmethod
    def process_events(events: List[Dict], client_dict: Dict[str, int]) -> Dict[str, Dict[str, Union[List[Dict], int]]]:
        logging.info("Processing events to find client matches...")
        clients_met = defaultdict(lambda: {'events': [], 'sessions': 0})
        for event in events:
            event_date_str = event['start'].get('dateTime', event['start'].get('date'))
            try:
                event_date = DataProcessor.parse_date(event_date_str)
            except ValueError:
                logging.warning(f"Unable to parse event date '{event_date_str}'. Skipping event.")
                continue

            event_title = event.get('summary', '')
            event_description = event.get('description', '')

            # Fuzzy matching: partials, case-insensitive
            for client in client_dict:
                client_parts = client.lower().split()
                if any(part in event_title.lower() or part in event_description.lower() for part in client_parts):
                    clients_met[client]['events'].append(event)
                    clients_met[client]['sessions'] += 1
                    break

        return clients_met

    @staticmethod
    def parse_date(date_str: str) -> datetime.date:
        date_str = date_str.strip()
        if not date_str:
            raise ValueError("Empty date string")
        try:
            # Attempt to parse ISO format first
            return datetime.strptime(date_str[:10], '%Y-%m-%d').date()
        except ValueError:
            # Fallback to MM/DD/YYYY
            return datetime.strptime(date_str, '%m/%d/%Y').date()


class GoogleCalendarSheetsAutomation:
    def __init__(self):
        self.gc = pygsheets.authorize(client_secret='client_secret.json')
        self.sheet_manager = SheetManager(self.gc, SPREADSHEET_NAME)
        creds = GoogleAuth.get_credentials()
        calendar_service = build('calendar', 'v3', credentials=creds)
        self.calendar_manager = CalendarManager(calendar_service)
        self.data_processor = DataProcessor()

    def run(self):
        try:
            logging.info("Starting the script...")
            try:
                self.create_backup()
                print("Backup created successfully.")
            except Exception as e:
                logging.error(f"Failed to create backup: {str(e)}")
                print(f"Failed to create backup. Error: {str(e)}")
                print("Do you want to continue without a backup? (y/n)")
                choice = input().strip().lower()
                if choice != 'y':
                    print("Exiting script.")
                    return

            if not self.clean_data():
                print("Exiting script as requested.")
                return

            self.clear_or_create_tabs()
            self.update_client_list()
            clients_met = self.process_calendar_events()
            if clients_met:
                self.create_sessions_tab(clients_met)
            self.reorder_tabs()
            if not self.add_unmatched_sessions():
                print("Exiting script as requested.")
                return

        except Exception as e:
            logging.error(f"An error occurred: {str(e)}")
            import traceback
            traceback.print_exc()
        finally:
            logging.info("Script execution completed.")

    def create_backup(self):
        logging.info("Creating backup of 'Sales & Sessions Completed' tab...")
        current_year = datetime.now().year
        sales_tab_name = f"Sales & Sessions Completed {current_year}"
        
        try:
            # Delete any existing backup to ensure only one backup exists
            existing_backup_sheets = [
                sheet for sheet in self.sheet_manager.spreadsheet.worksheets() 
                if sheet.title.startswith(f"BACKUP_{sales_tab_name}")
            ]
            for sheet in existing_backup_sheets:
                self.sheet_manager.spreadsheet.del_worksheet(sheet)
                logging.info(f"Deleted existing backup: '{sheet.title}'")
            
            sales_sheet = self.sheet_manager.get_sheet(sales_tab_name)
            backup_name = f"BACKUP_{sales_tab_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            backup_sheet = self.sheet_manager.spreadsheet.add_worksheet(backup_name)
            
            # Step 1: Copy all data from the original sheet to the backup
            data = sales_sheet.get_all_values()
            
            # Get the dimensions of the original sheet
            rows = len(data)
            cols = len(data[0]) if data else 0
            
            # Resize the backup sheet to match the original
            backup_sheet.resize(rows=rows, cols=cols)
            
            # Copy data in chunks to avoid exceeding limits
            chunk_size = 1000  # Adjust this value if needed
            for i in range(0, rows, chunk_size):
                end = min(i + chunk_size, rows)
                backup_sheet.update_values(f'A{i+1}', data[i:end])
            
            logging.info("Data copied successfully.")
            logging.info(f"Backup created: '{backup_name}'")
        except Exception as e:
            logging.error(f"Failed to create backup: {str(e)}")
            raise

    def clean_data(self) -> bool:
        logging.info("Starting data cleaning process...")
        current_year = datetime.now().year
        sales_tab_name = f"Sales & Sessions Completed {current_year}"
        sales_sheet = self.sheet_manager.get_sheet(sales_tab_name)
        sales_data = sales_sheet.get_all_values()

        if not sales_data:
            logging.warning(f"'{sales_tab_name}' tab is empty. Skipping data cleaning.")
            return True

        headers = sales_data[0]
        date_col = headers.index("DATE")

        fix_all_dates = False
        date_updates = []
        rows_updated = 0

        for i, row in enumerate(sales_data[1:], start=2):
            date = row[date_col].strip()
            if not date:
                continue  # Skip empty date cells
            try:
                formatted_date = self.format_date(date)
                if formatted_date != date:
                    if not fix_all_dates:
                        choice = input(
                            f"Row {i}: Current date '{date}' will be formatted to '{formatted_date}'. Fix this date? (y/n/q/Y to fix all): "
                        ).strip()
                        if choice.lower() == 'q':
                            logging.info("User chose to quit. Stopping data cleaning.")
                            return False  # Exit the cleaning process
                        elif choice == 'Y':
                            fix_all_dates = True
                        elif choice.lower() == 'y':
                            date_updates.append([i, date_col + 1, formatted_date])
                            rows_updated += 1
                        elif choice.lower() == 'n':
                            continue  # Skip this row and move to the next one
                    
                    if fix_all_dates:
                        date_updates.append([i, date_col + 1, formatted_date])
                        rows_updated += 1
            except ValueError:
                logging.warning(f"Unable to parse date '{date}' in row {i}. Skipping.")
        
        if date_updates:
            logging.info(f"Applying {len(date_updates)} date updates in batch...")
            try:
                # Prepare batch update requests
                sheet_id = sales_sheet.id
                requests = []
                for row, col, value in date_updates:
                    requests.append({
                        "updateCells": {
                            "rows": [{
                                "values": [{
                                    "userEnteredValue": {
                                        "stringValue": value
                                    }
                                }]
                            }],
                            "fields": "userEnteredValue",
                            "start": {
                                "sheetId": sheet_id,
                                "rowIndex": row - 1,       # Sheets API is 0-based
                                "columnIndex": col - 1     # Sheets API is 0-based
                            }
                        }
                    })

                # Execute batch update
                sales_sheet.batch_update(requests)
                logging.info(f"Batch update completed. Successfully updated {rows_updated} row(s).")
                print(f"Successfully updated {rows_updated} row(s).")
            except Exception as e:
                logging.error(f"Failed to apply batch updates: {str(e)}")
                print(f"Failed to apply batch updates: {str(e)}")
                return False

        logging.info("Data cleaning process completed.")
        return True  # Indicate successful completion

    def format_date(self, date_str: str) -> str:
        date_str = date_str.strip()
        if not date_str:
            raise ValueError("Empty date string")
        
        # Try parsing with various formats
        for fmt in ('%m/%d/%Y', '%Y-%m-%d', '%d-%m-%Y', '%m-%d-%Y'):
            try:
                return datetime.strptime(date_str, fmt).strftime('%m/%d/%Y')
            except ValueError:
                pass
        
        raise ValueError(f"Unable to parse date: {date_str}")

    def clear_or_create_tabs(self):
        self.sheet_manager.clear_or_create_tab("CLIENT LIST")
        self.sheet_manager.clear_or_create_tab("LAST WEEK")
        logging.info("Tabs 'CLIENT LIST' and 'LAST WEEK' are ready.")

    def update_client_list(self):
        sales_sheet = self.sheet_manager.find_sales_sheet(datetime.now().year)
        logging.info(f"Found '{sales_sheet.title}' tab.")

        logging.info("Fetching client names...")
        client_name_col = sales_sheet.find("CLIENT NAME")[0].col
        client_names = sales_sheet.get_col(client_name_col, include_tailing_empty=False)[1:]
        logging.info(f"Found {len(client_names)} client names.")

        logging.info("Counting sessions for each client...")
        session_counts = {}
        for name in client_names:
            session_counts[name] = session_counts.get(name, 0) + 1

        unique_client_names = sorted(set(client_names))
        logging.info(f"Found {len(unique_client_names)} unique clients.")

        logging.info("Opening 'CLIENT LIST' tab...")
        client_list_sheet = self.sheet_manager.get_sheet("CLIENT LIST")

        logging.info("Updating column headers...")
        client_list_sheet.update_values('A1:B1', [['CLIENT NAME', 'SESSIONS COMPLETED']])

        if unique_client_names:
            logging.info("Preparing data for updating...")
            update_data = [
                [name, session_counts.get(name, 0)]
                for name in unique_client_names
            ]

            update_data.sort(key=lambda x: x[1], reverse=True)
    
            logging.info("Clearing existing data...")
            client_list_sheet.clear('A2')
            logging.info("Updating with new data...")
google-auth-oauthlib==0.4.6
google-auth-httplib2==0.1.0
google-api-python-client==2.47.0
pygsheets==2.0.5